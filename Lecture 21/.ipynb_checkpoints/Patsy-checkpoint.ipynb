{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Patsy**\n",
    "\n",
    "Patsy is a nice package for setting up linear models for fitting in sklearn.\n",
    "\n",
    "It creates the matrices needed for modeling various methods (like regression) in sklearn\n",
    "\n",
    "- the matrix of predictor variable columns aka the *design matrix*\n",
    "- the column of response variable values\n",
    "\n",
    "It allows us to specify models using *formulas* (as in R) rather than by doing things by hand.\n",
    "\n",
    "To illustrate it use, we return to the traffic prediction problem. \n",
    "\n",
    "We'll recode weekdays as strings (object) to illustrate what patsy does with a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Tue\n",
       "1        Tue\n",
       "2        Tue\n",
       "3        Tue\n",
       "4        Tue\n",
       "        ... \n",
       "40566    Sun\n",
       "40567    Sun\n",
       "40568    Sun\n",
       "40569    Sun\n",
       "40570    Sun\n",
       "Name: dayofweek, Length: 40571, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import mylib as my\n",
    "from sklearn.linear_model import LinearRegression\n",
    "os.chdir(my.onedrive+\"//CurrentCourses/553.688.Spring.2023/Lectures/April/Lecture22/\")\n",
    "df=pd.read_csv(\"TRAFFIC_VOLUME2.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\",\"index\",\"weather_description\",\"time_diff\",\"snow_1h\",\"holiday\"],inplace=True)\n",
    "df[\"dayofweek\"]=df.weekday.map({0:\"Mon\",1:\"Tue\",2:\"Wed\",3:\"Thu\",4:\"Fri\",5:\"Sat\",6:\"Sun\"})\n",
    "N=df.shape[0] # number of rows\n",
    "perm=np.random.permutation(range(N))\n",
    "Itrain1=perm[0:int(N/3)]\n",
    "Itrain2=perm[int(N/3):int(2*N/3)]\n",
    "Itest=perm[int(2*N/3):N]\n",
    "dfTrain1=df.loc[Itrain1]\n",
    "dfTrain2=df.loc[Itrain2]\n",
    "dfTest=df.loc[Itest]\n",
    "df.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple example**\n",
    "\n",
    "In the following we tell patsy to create the matrices for predicting traffic_volume \n",
    "using a combination of numerical and categorical predictor variables.\n",
    "\n",
    "Patsy automatically includes an intercept in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy as ps\n",
    "\n",
    "formula=\"traffic_volume~dayofweek+dayofyear\"\n",
    "Ytrain1,Xtrain1=ps.dmatrices(formula, dfTrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (13523, 1)\n",
       "  traffic_volume\n",
       "             891\n",
       "             312\n",
       "            4322\n",
       "            4259\n",
       "            5650\n",
       "            5466\n",
       "            5833\n",
       "            3996\n",
       "            1740\n",
       "            1853\n",
       "            3282\n",
       "             827\n",
       "            3038\n",
       "            2635\n",
       "            4860\n",
       "            4882\n",
       "            4295\n",
       "            5227\n",
       "             800\n",
       "            2176\n",
       "            3385\n",
       "            4471\n",
       "             731\n",
       "            4238\n",
       "            5747\n",
       "            3422\n",
       "            2943\n",
       "            2558\n",
       "            3282\n",
       "             396\n",
       "  [13493 rows omitted]\n",
       "  Terms:\n",
       "    'traffic_volume' (column 0)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0.   0. ...   1.   0. 253.]\n",
      " [  1.   1.   0. ...   0.   0. 120.]\n",
      " [  1.   0.   0. ...   0.   0. 348.]\n",
      " ...\n",
      " [  1.   1.   0. ...   0.   0. 249.]\n",
      " [  1.   0.   0. ...   1.   0. 153.]\n",
      " [  1.   0.   0. ...   0.   0. 155.]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that patsy created 6 dummy variables, one for each weekday, and left out friday as reference day.\n",
    "We an inspect the columns using that last suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(Xtrain1)[0:100,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, as usual we can use the X, Y values to fit a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13523, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit=LinearRegression().fit(Xtrain1,Ytrain1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the test matrices**\n",
    "\n",
    "We need to apply the same algorithm for creating the design matrix for the test data (or the second training dataset) that was applied to the first training set.\n",
    "\n",
    "Be careful!!! Consider the following example of what can go wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day  calories   wt\n",
      "0  Mon      1400  145\n",
      "1  Tue      1800  147\n",
      "2  Wed      2100  149\n",
      "3  Thu      2000  148\n",
      "4  Mon      1900  147\n",
      "5  Tue      1800  148\n",
      "6  Wed      1500  150\n",
      "7  Thu      1800  149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.42307692e+00, 1.45384615e+00, 3.45384615e+00,\n",
       "        3.07692308e-04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1=pd.DataFrame({\"day\":[\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Mon\",\"Tue\",\"Wed\",\"Thu\"],\n",
    "                  \"calories\":[1400,1800,2100,2000,1900,1800,1500,1800],\n",
    "                  \"wt\":[145,147,149,148,147,148,150,149]})\n",
    "print(dt1)\n",
    "Y1,X1=ps.dmatrices(\"wt~day+calories\",dt1)\n",
    "X1\n",
    "fit=LinearRegression().fit(X1,Y1)\n",
    "fit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0e+00 0.0e+00 0.0e+00 0.0e+00 1.4e+03]\n",
      " [1.0e+00 0.0e+00 1.0e+00 0.0e+00 1.8e+03]\n",
      " [1.0e+00 0.0e+00 0.0e+00 1.0e+00 2.1e+03]\n",
      " [1.0e+00 1.0e+00 0.0e+00 0.0e+00 2.0e+03]\n",
      " [1.0e+00 0.0e+00 0.0e+00 0.0e+00 1.9e+03]\n",
      " [1.0e+00 0.0e+00 1.0e+00 0.0e+00 1.8e+03]\n",
      " [1.0e+00 0.0e+00 0.0e+00 1.0e+00 1.5e+03]\n",
      " [1.0e+00 1.0e+00 0.0e+00 0.0e+00 1.8e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Monday was made the reference day.\n",
    "Now consider data we want to make predictions for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day  calories   wt\n",
      "0  Thu      1500  148\n",
      "1  Mon      1300  147\n",
      "2  Thu      1700  146\n",
      "3  Mon      2000  149\n",
      "4  Thu      1900  147\n",
      "5  Mon      1800  149\n",
      "6  Thu      1800  150\n",
      "7  Mon      1900  151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (8, 3)\n",
       "  Intercept  day[T.Thu]  calories\n",
       "          1           1      1500\n",
       "          1           0      1300\n",
       "          1           1      1700\n",
       "          1           0      2000\n",
       "          1           1      1900\n",
       "          1           0      1800\n",
       "          1           1      1800\n",
       "          1           0      1900\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'day' (column 1)\n",
       "    'calories' (column 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2=pd.DataFrame({\"day\":[\"Thu\",\"Mon\",\"Thu\",\"Mon\",\"Thu\",\"Mon\",\"Thu\",\"Mon\"],\n",
    "                  \"calories\":[1500,1300,1700,2000,1900,1800,1800,1900],\n",
    "                  \"wt\":[148,147,146,149,147,149,150,151]})\n",
    "print(dt2)\n",
    "Y2,X2=ps.dmatrices(\"wt~day+calories\",dt2)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but LinearRegression is expecting 5 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3484\\2032060293.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \"\"\"\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 3 features, but LinearRegression is expecting 5 features as input."
     ]
    }
   ],
   "source": [
    "fit.predict(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a problem. We want to make sure that the same process is applied to the new data for creating the design matrix. \n",
    "\n",
    "We can do that using the following approach which basically says to use info about how X1 was created (formula and the data frame) to build a design matrix for a new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=ps.build_design_matrices([X1.design_info], dt2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (8, 5)\n",
       "  Intercept  day[T.Thu]  day[T.Tue]  day[T.Wed]  calories\n",
       "          1           1           0           0      1500\n",
       "          1           0           0           0      1300\n",
       "          1           1           0           0      1700\n",
       "          1           0           0           0      2000\n",
       "          1           1           0           0      1900\n",
       "          1           0           0           0      1800\n",
       "          1           1           0           0      1800\n",
       "          1           0           0           0      1900\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'day' (columns 1:4)\n",
       "    'calories' (column 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148.37692308],\n",
       "       [145.89230769],\n",
       "       [148.43846154],\n",
       "       [146.10769231],\n",
       "       [148.5       ],\n",
       "       [146.04615385],\n",
       "       [148.46923077],\n",
       "       [146.07692308]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.predict(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional things you can do with patsy formulas**\n",
    "\n",
    "We can tell patsy not to include an interecept parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (13523, 8)\n",
       "  Columns:\n",
       "    ['dayofweek[Fri]',\n",
       "     'dayofweek[Mon]',\n",
       "     'dayofweek[Sat]',\n",
       "     'dayofweek[Sun]',\n",
       "     'dayofweek[Thu]',\n",
       "     'dayofweek[Tue]',\n",
       "     'dayofweek[Wed]',\n",
       "     'day']\n",
       "  Terms:\n",
       "    'dayofweek' (columns 0:7), 'day' (column 7)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula=\"traffic_volume~0+day+dayofweek\"\n",
    "Ytrain1,Xtrain1=ps.dmatrices(formula, dfTrain1)\n",
    "Xtrain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can include transformations of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (13523, 4)\n",
       "  Columns:\n",
       "    ['Intercept',\n",
       "     'day',\n",
       "     'np.sin(2 * np.pi * dayofyear / 365)',\n",
       "     'np.cos(2 * np.pi * dayofyear / 365)']\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'day' (column 1)\n",
       "    'np.sin(2 * np.pi * dayofyear / 365)' (column 2)\n",
       "    'np.cos(2 * np.pi * dayofyear / 365)' (column 3)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula=\"traffic_volume~day+np.sin(2*np.pi*dayofyear/365)+np.cos(2*np.pi*dayofyear/365)\"\n",
    "Ytrain1,Xtrain1=ps.dmatrices(formula, dfTrain1)\n",
    "Xtrain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can include interactions between categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temp', 'rain_1h', 'clouds_all', 'weather_main', 'date_time',\n",
       "       'traffic_volume', 'date', 'time', 'year', 'day1ofyear', 'dayofyear',\n",
       "       'hour', 'weekday', 'day', 'lrain', 'snowind', 'holiday_ind', 'daysin',\n",
       "       'daycos', 'dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (13523, 64)\n",
       "  Columns:\n",
       "    ['Intercept',\n",
       "     'weather_main[T.Clouds]',\n",
       "     'weather_main[T.Drizzle]',\n",
       "     'weather_main[T.Haze]',\n",
       "     'weather_main[T.Mist]',\n",
       "     'weather_main[T.Other]',\n",
       "     'weather_main[T.Rain]',\n",
       "     'weather_main[T.Snow]',\n",
       "     'weather_main[T.Thunderstorm]',\n",
       "     'dayofweek[T.Mon]',\n",
       "     'dayofweek[T.Sat]',\n",
       "     'dayofweek[T.Sun]',\n",
       "     'dayofweek[T.Thu]',\n",
       "     'dayofweek[T.Tue]',\n",
       "     'dayofweek[T.Wed]',\n",
       "     'weather_main[T.Clouds]:dayofweek[T.Mon]',\n",
       "     'weather_main[T.Drizzle]:dayofweek[T.Mon]',\n",
       "     'weather_main[T.Haze]:dayofweek[T.Mon]',\n",
       "     'weather_main[T.Mist]:dayofweek[T.Mon]',\n",
       "     'weather_main[T.Other]:dayofweek[T.Mon]',\n",
       "     'weather_main[T.Rain]:dayofweek[T.Mon]',\n",
       "     'weather_main[T.Snow]:dayofweek[T.Mon]',\n",
       "     'weather_main[T.Thunderstorm]:dayofweek[T.Mon]',\n",
       "     'weather_main[T.Clouds]:dayofweek[T.Sat]',\n",
       "     'weather_main[T.Drizzle]:dayofweek[T.Sat]',\n",
       "     'weather_main[T.Haze]:dayofweek[T.Sat]',\n",
       "     'weather_main[T.Mist]:dayofweek[T.Sat]',\n",
       "     'weather_main[T.Other]:dayofweek[T.Sat]',\n",
       "     'weather_main[T.Rain]:dayofweek[T.Sat]',\n",
       "     'weather_main[T.Snow]:dayofweek[T.Sat]',\n",
       "     'weather_main[T.Thunderstorm]:dayofweek[T.Sat]',\n",
       "     'weather_main[T.Clouds]:dayofweek[T.Sun]',\n",
       "     'weather_main[T.Drizzle]:dayofweek[T.Sun]',\n",
       "     'weather_main[T.Haze]:dayofweek[T.Sun]',\n",
       "     'weather_main[T.Mist]:dayofweek[T.Sun]',\n",
       "     'weather_main[T.Other]:dayofweek[T.Sun]',\n",
       "     'weather_main[T.Rain]:dayofweek[T.Sun]',\n",
       "     'weather_main[T.Snow]:dayofweek[T.Sun]',\n",
       "     'weather_main[T.Thunderstorm]:dayofweek[T.Sun]',\n",
       "     'weather_main[T.Clouds]:dayofweek[T.Thu]',\n",
       "     'weather_main[T.Drizzle]:dayofweek[T.Thu]',\n",
       "     'weather_main[T.Haze]:dayofweek[T.Thu]',\n",
       "     'weather_main[T.Mist]:dayofweek[T.Thu]',\n",
       "     'weather_main[T.Other]:dayofweek[T.Thu]',\n",
       "     'weather_main[T.Rain]:dayofweek[T.Thu]',\n",
       "     'weather_main[T.Snow]:dayofweek[T.Thu]',\n",
       "     'weather_main[T.Thunderstorm]:dayofweek[T.Thu]',\n",
       "     'weather_main[T.Clouds]:dayofweek[T.Tue]',\n",
       "     'weather_main[T.Drizzle]:dayofweek[T.Tue]',\n",
       "     'weather_main[T.Haze]:dayofweek[T.Tue]',\n",
       "     'weather_main[T.Mist]:dayofweek[T.Tue]',\n",
       "     'weather_main[T.Other]:dayofweek[T.Tue]',\n",
       "     'weather_main[T.Rain]:dayofweek[T.Tue]',\n",
       "     'weather_main[T.Snow]:dayofweek[T.Tue]',\n",
       "     'weather_main[T.Thunderstorm]:dayofweek[T.Tue]',\n",
       "     'weather_main[T.Clouds]:dayofweek[T.Wed]',\n",
       "     'weather_main[T.Drizzle]:dayofweek[T.Wed]',\n",
       "     'weather_main[T.Haze]:dayofweek[T.Wed]',\n",
       "     'weather_main[T.Mist]:dayofweek[T.Wed]',\n",
       "     'weather_main[T.Other]:dayofweek[T.Wed]',\n",
       "     'weather_main[T.Rain]:dayofweek[T.Wed]',\n",
       "     'weather_main[T.Snow]:dayofweek[T.Wed]',\n",
       "     'weather_main[T.Thunderstorm]:dayofweek[T.Wed]',\n",
       "     'day']\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'weather_main' (columns 1:9)\n",
       "    'dayofweek' (columns 9:15)\n",
       "    'weather_main:dayofweek' (columns 15:63)\n",
       "    'day' (column 63)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula=\"traffic_volume~day+weather_main*dayofweek\"\n",
    "Ytrain1,Xtrain1=ps.dmatrices(formula, dfTrain1)\n",
    "Xtrain1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing**\n",
    "\n",
    "For some procedures you are advised to normalize your variables before fitting a model.\n",
    "Again, whatever normalization you use should be first defined on the training data and that normalization should be applied to the test data.\n",
    "\n",
    "This is best explained in an example.\n",
    "\n",
    "Q: If we normalize the rain_1h variable by subtracing the mean and dividing by the standard deviation of that variable, which mean and std deviation should we use?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
